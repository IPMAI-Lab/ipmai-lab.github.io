<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Yake Wei | GeWu-Lab</title>
    <link>/authors/yake-wei/</link>
      <atom:link href="/authors/yake-wei/index.xml" rel="self" type="application/rss+xml" />
    <description>Yake Wei</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>copyright Â© 2024 GeWu-Lab</copyright>
    <image>
      <url>/img/logo.png</url>
      <title>Yake Wei</title>
      <link>/authors/yake-wei/</link>
    </image>
    
    <item>
      <title>Balanced Multimodal Learning via On-the-fly Gradient Modulation</title>
      <link>/publication/balanced-multimodal-learning-via-on-the-fly-gradient-modulation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/balanced-multimodal-learning-via-on-the-fly-gradient-modulation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Class-aware Sounding Objects Localization via Audiovisual Correspondence</title>
      <link>/publication/class-aware-sounding-objects-localization-via-audiovisual-correspondence/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/class-aware-sounding-objects-localization-via-audiovisual-correspondence/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Enhancing Multi-modal Cooperation via Fine-grained Modality Valuation</title>
      <link>/publication/enhancing-multi-modal-cooperation-via-fine-grained-modality-valuation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/enhancing-multi-modal-cooperation-via-fine-grained-modality-valuation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Geometric-Inspired Graph-based Incomplete Multi-view Clustering</title>
      <link>/publication/geometric-inspired-graph-based-incomplete-multi-view-clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/geometric-inspired-graph-based-incomplete-multi-view-clustering/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning in Audio-visual Context: A Review, Analysis, and New Perspective</title>
      <link>/publication/learning-in-audio-visual-context-a-review-analysis-and-new-perspective/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/learning-in-audio-visual-context-a-review-analysis-and-new-perspective/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Learning to Answer Questions in Dynamic Audio-Visual Scenarios</title>
      <link>/publication/learning-to-answer-questions-in-dynamic-audio-visual-scenarios/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/learning-to-answer-questions-in-dynamic-audio-visual-scenarios/</guid>
      <description></description>
    </item>
    
    <item>
      <title>MMPareto: Innocent Uni-modal Assistance for Enhanced Multi-modal Learning</title>
      <link>/publication/mmpareto-innocent-uni-modal-assistance-for-enhanced-multi-modal-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/mmpareto-innocent-uni-modal-assistance-for-enhanced-multi-modal-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Quantifying and Enhancing Multi-modal Robustness with Modality Preference</title>
      <link>/publication/quantifying-and-enhancing-multi-modal-robustness-with-modality-preference/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/quantifying-and-enhancing-multi-modal-robustness-with-modality-preference/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
