<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Wenke Xia* | GeWu-Lab</title>
    <link>/authors/wenke-xia/</link>
      <atom:link href="/authors/wenke-xia/index.xml" rel="self" type="application/rss+xml" />
    <description>Wenke Xia*</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>copyright Â© 2023 GeWu-Lab</copyright>
    <image>
      <url>/img/logo.png</url>
      <title>Wenke Xia*</title>
      <link>/authors/wenke-xia/</link>
    </image>
    
    <item>
      <title>Balanced Audiovisual Dataset for Imbalance Analysis</title>
      <link>/publication/balanced-audiovisual-dataset-for-imbalance-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/balanced-audiovisual-dataset-for-imbalance-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Kinematic-aware Prompting for Generalizable Articulated Object Manipulation with LLMs</title>
      <link>/publication/kinematic-aware-prompting-for-generalizable-articulated-object-manipulation-with-llms/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/kinematic-aware-prompting-for-generalizable-articulated-object-manipulation-with-llms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Revisiting Pre-training in Audio-Visual Learning</title>
      <link>/publication/revisiting-pre-training-in-audio-visual-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/revisiting-pre-training-in-audio-visual-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Robust Cross-modal Knowledge Distillation for Unconstrained Videos</title>
      <link>/publication/robust-cross-modal-knowledge-distillation-for-unconstrained-videos/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/robust-cross-modal-knowledge-distillation-for-unconstrained-videos/</guid>
      <description></description>
    </item>
    
    <item>
      <title>TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World</title>
      <link>/publication/tiktalk-a-video-based-dialogue-dataset-for-multi-modal-chitchat-in-real-world/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/tiktalk-a-video-based-dialogue-dataset-for-multi-modal-chitchat-in-real-world/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
