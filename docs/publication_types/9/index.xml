<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>9 | GeWu-Lab</title>
    <link>/publication_types/9/</link>
      <atom:link href="/publication_types/9/index.xml" rel="self" type="application/rss+xml" />
    <description>9</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>copyright Â© 2025 GeWu-Lab</copyright>
    <image>
      <url>/img/logo.png</url>
      <title>9</title>
      <link>/publication_types/9/</link>
    </image>
    
    <item>
      <title>A Two-Stage Framework for Multiple Sound-Source Localization</title>
      <link>/publication/a-two-stage-framework-for-multiple-sound-source-localization/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/a-two-stage-framework-for-multiple-sound-source-localization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Adaptive Unimodal Regulation for Balanced Multimodal Information Acquisition</title>
      <link>/publication/adaptive-unimodal-regulation-for-balanced-multimodal-information-acquisition/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/adaptive-unimodal-regulation-for-balanced-multimodal-information-acquisition/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Balanced Audiovisual Dataset for Imbalance Analysis</title>
      <link>/publication/balanced-audiovisual-dataset-for-imbalance-analysis/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/balanced-audiovisual-dataset-for-imbalance-analysis/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Co-Learn Sounding Object Visual Grounding and Visually Indicated Sound Separation in A Cycle</title>
      <link>/publication/co-learn-sounding-object-visual-grounding-and-visually-indicated-sound-separation-in-a-cycle/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/co-learn-sounding-object-visual-grounding-and-visually-indicated-sound-separation-in-a-cycle/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Crab: A Unified Audio-Visual Scene Understanding Model with Explicit Cooperation</title>
      <link>/publication/crab-a-unified-audio-visual-scene-understanding-model-with-explicit-cooperation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/crab-a-unified-audio-visual-scene-understanding-model-with-explicit-cooperation/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Does Ambient Sound Help? - Audiovisual Crowd Counting</title>
      <link>/publication/does-ambient-sound-help_-audiovisual-crowd-counting/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/does-ambient-sound-help_-audiovisual-crowd-counting/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Geometric-Inspired Graph-based Incomplete Multi-view Clustering</title>
      <link>/publication/geometric-inspired-graph-based-incomplete-multi-view-clustering/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/geometric-inspired-graph-based-incomplete-multi-view-clustering/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Heterogeneous Scene Analysis via Self-supervised Audiovisual Learning</title>
      <link>/publication/heterogeneous-scene-analysis-via-self-supervised-audiovisual-learning/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/heterogeneous-scene-analysis-via-self-supervised-audiovisual-learning/</guid>
      <description></description>
    </item>
    
    <item>
      <title>KOI: Accelerating Online Imitation Learning via Hybrid Key-state Guidance</title>
      <link>/publication/koi_-accelerating-online-imitation-learning-via-hybrid-key-state-guidance/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/koi_-accelerating-online-imitation-learning-via-hybrid-key-state-guidance/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Phoenix: A Motion-based Self-Reflection Framework for Fine-grained Robotic Action Correction</title>
      <link>/publication/phoenix-a-motion-based-self-reflection-framework-for-fine-grained-robotic-action-correction-/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/phoenix-a-motion-based-self-reflection-framework-for-fine-grained-robotic-action-correction-/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Play to the Score: Stage-Guided Dynamic Multi-Sensory Fusion for Robotic Manipulation</title>
      <link>/publication/play-to-the-score_-stage-guided-dynamic-multi-sensory-fusion-for-robotic-manipulation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>/publication/play-to-the-score_-stage-guided-dynamic-multi-sensory-fusion-for-robotic-manipulation/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>
